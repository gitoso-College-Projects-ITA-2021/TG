\section{Firmware}

Firmware is a class of computer software that is built for a specific embedded hardware with the goal to provide basic functionalities and act as an operational system. Firmware can be very different from each other and may vary greatly between vendors. Usually firmware is part of the equipment and is held in the device's non-volatile memory, such as ROM, EPROM, EEPROM and flash memory. In this research work, we focus our attention in wireless router firmware and most specifically in those who are based on the Linux operating system.

\section{Re-Hosting}

Re-hosting specifies that a binary that would run on a specific hardware is instead run on a host system using system emulation and is therefore ``re-hosted'' \cite{firmware-challenges}. Firmware re-hosting in this context relates to executing the firmware, that was originally designed to run on the original hardware, on a desktop computer (i.e. not in the physical hardware it was designed to). Re-hosting challenges involve executing binaries that were designed to run on a specific processor architecture on another. This is usually done using an emulator software.

One very popular open source tool for architecture emulation is the QEMU framework, that does dynamic binary translation: guest CPU instructions are converted to the host CPU instructions, converting them to work with the change in CPU architecture. QEMU is a complex tool that implements a lot of optimizations to this translation process. It also leverages Linux kernel features from the host (if available) to enhance emulation speed.

\section{Software Vulnerability}

Although there are many ways to describe a software vulnerability, one that is close to the software engineering field is that a software vulnerability is an instance of a mistake in the specification, development or configuration of software such that its execution can violate the explicit or implicit security policies \cite{vuln-discovery}. By this definition, one mistake can incur in different vulnerabilities inside a software product.

Companies have put increasingly effort on the adoption of secure software development techniques in early stages of product implementation in order to avoid making mistakes that can lead to vulnerabilities. Even so, software development is a really extensive task and even experienced developers can sometimes make mistakes.

Software vulnerabilities may be exploited by malicious actors to gain access to damage a product or to gain access to sensitive information. Therefore, it is important for companies and security researchers to have effective ways to find vulnerabilities within their products, so that they can update the product to patch these vulnerabilities and provide more security to their business and to their customers. Efficiency in this process is also highly desirable as the latter vulnerabilities are discovered, it becomes more and more expensive to remediate them \cite{soft-eng-economics}.

\subsection{Vulnerability Discovery}
\label{subsec:vuln-disc}

Given the importance of the vulnerability discovery process, some techniques were developed to assist human specialists in this process and these techniques are moving towards becoming more and more automated, such as in the future we may have complete Cyber Reasoning Systems (CRS) working in this process of vulnerability disclosure \cite{crs}.

Nowadays, human specialists are still the main source of vulnerability discovery and the main techniques used in this process are: static analysis, dynamic analysis, symbolic execution and fuzzing. In the following subsections, we will briefly explain how each of these techniques work, and in Table \ref{tab:disc-techniques} we compare these techniques \cite{fuzzing}.

\begin{table}[h]
    \centering
    \caption{Comparison between vulnerability discovery techniques}
        \begin{tabular}{|c|c|c|c|}
        \hline
        \textbf{Technique}   & \textbf{Initial Complexity} & \textbf{Accuracy} & \textbf{Scalability} \\ \hline
        Static Analysis    & Easy      & Low   & Good         \\ \hline
        Dynamic Analysis   & Hard      & High  & Uncertain    \\ \hline
        Symbolic Execution & Hard      & High  & Bad          \\ \hline
        Fuzzing            & Easy      & High  & Good         \\ \hline
        \end{tabular}%
    \label{tab:disc-techniques}
\end{table}

\subsubsection{Static Analysis}

Static analysis consists in searching for vulnerabilities in a software without really executing its code. Static analysis is performed by searching the source code (it can be the object code too, but is a lot harder) for known syntax that may lead to bugs. Static analysis can be automated and tools can be quickly used to search inside a codebase for semantics that appear to be vulnerable. The downside of static analysis is that its simplistic approach is prone to result in a lot of false-positives, and it requires some specialist to read the automated reports to filter the results.

As this analysis is easily automated and quick to execute, it is best used during the development process, and may be even incorporated to the software production pipeline.

\subsubsection{Dynamic Analysis}

In contrast to static analysis in which the software is not executed, dynamic analysis is the process of searching for vulnerabilities in a software during its execution. Software state and execution flow can be monitored during software execution, and a human specialist with strong technical skills in analysis can use this monitored execution environment to find bugs precisely. That being said, this technique is extremely accurate, but also very dependent on the intervention of a human with strong technical skills, restraining the automation of this kind of analysis.

\subsubsection{Symbolic Execution}

Symbolic execution can be considered a specific form of automated dynamic analysis in which the program is executed in a controlled and instrumented environment and each input read by the program is treated as a symbol. When the assembly code reaches a branch instruction that depends on the value of this symbol, then the program takes note of each value constraints for each symbol. This way, knowing every symbol and constraint equation, a symbolic solver could be used to map values for the symbols in such way that every code flow is reached.

This method has been proven to be extremely accurate in small, simple programs. However, when the code grows, the symbolic execution faces the \textit{path explosion} problem. The number of possible paths becomes so big that it becomes impossible for the solvers we have available to calculate every execution flow.

\subsubsection{Fuzzing}

Fuzzing can also be considered a specific form of an automated dynamic analysis. This technique consists of generating a massive amount of normal and abnormal inputs and feeding the target program with these generated inputs. Execution state is then monitored to identify if any of the inputs corrupted the execution flow. Fuzzing technique is easy to be deployed, with high accuracy as it is done in the real execution, and also easy to be scaled. However, fuzzing still has issues with low efficiency and code coverage, but as it is also a relatively new technique, a lot of research is being developed upon enhancing this technique, that has already become the state-of-art vulnerability discovery technique currently \cite{fuzzing}.


\subsection{Challenges in Vulnerability Discovery for IoT}

Regarding the vulnerability discovery methods presented in section \ref{subsec:vuln-disc}, these methods were developed to find vulnerabilities in general purpose computers such as home computers or servers. When trying to discover vulnerabilities in software developed for embedded hardware, researchers may face additional challenges.

The first challenge may be the acquisition of the target software. Many firmware images were only developed to work within their original hardware, and the only way to have a copy of the software may be opening the hardware and extracting the original system from one of its memories.

Another challenge is the dependency of the hardware. Firmware images are usually tied to the original hardware they were designed to operate with. To apply vulnerability discovery techniques in firmware files, we have to re-host the firmware so that it can be run inside an emulator and there we can apply the vulnerability discovery techniques. Usually, re-hosting is a process with a lot of challenges by its own.

An additional challenge presented by firmware images that don't use a general purpose operating system (such as Linux, FreeRTOS, VxWorks) or firmwares that are really lean is that the vulnerability discovery methods aforementioned rely on monitoring operating system calls that indicate memory corruption. If the firmware don't implement security mechanisms that indicate memory corruption, it becomes a lot harder to automatically detect that the firmware execution reached an abnormal state (caused by the exploitation of an existent vulnerability) \cite{wycinwyc}.