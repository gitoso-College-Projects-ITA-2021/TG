Regarding how to overcome re-hosting difficulties caused by the need of peripherals of the original hardware that are not present in the emulated device, researchers have developed different approaches. The work of \cite{firmware-challenges} surveys the most prominent techniques used in firmware re-hosting to bypass real hardware dependency. The four most common approaches are: Partial Emulation, Fuzzing, Learning and Abstraction Replacement.

\section{Partial Emulation}

Partial emulation, also known as ``hardware in the loop'' consists of emulating most part of firmware execution, but redirecting to the real device hardware calls when the firmware asks for a peripheral that can't be emulated. This approach requires having a real device available, and for this reason it does not scale. Execution fidelity in other hand is pretty close to the real hardware execution. The work of \cite{surrogates} enhances hardware redirecting by building a hardware bridge using an FPGA board to connect the PCI bus on the emulating host with the PCI bus on the real embedded device, an approach they called {\tt SURROGATES}.

The work of \cite{avatar2} greatly explores vulnerability discovery in embedded devices using the hardware in the loop technique. They use a symbolic engine build upon QEMU called {\tt S2E} to search for vulnerabilities in IoT devices through re-hosting and redirecting peripherals calls to the real hardware. They implement a tool called {\tt AvatarÂ²} as a reverse engineering framework based on hardware in the loop approach.

\section{Fuzzing}

Fuzzing as a re-hosting approach to hardware dependence (not to be confused with fuzzing as a vulnerability discovery technique) is based on the fact that hardware calls to peripherals don't really need the peripheral to be successful. The real peripheral ``answer'' to the hardware call is just a binary value. Knowing the range of values that provide an accepted answer to the hardware call, selecting any random value withing this range will be enough to keep executing the emulated system.

One way to effectively implement this kind of hardware bypass is proposed in the work of \cite{p2im} in which the authors present an approach to model the interface between the processor and the peripheral. The method suggested is called {\tt P2IM} - Processor-Peripheral Interface Modeling, and it requires a human specialist to model the interface between the CPU and a specific peripheral in order to determine the specific range of values to each hardware call.

As this approach required human intervention (to model the interface) it is also not a scalable solution.

\section{Learning}

Learning is a similar approach to fuzzing for re-hosting, as it relies on the fact that to bypass hardware dependence it is only needed to return expected values to hardware calls. However, the learning approach, as used in \cite{pretender} first monitor real hardware execution and registers each hardware-peripheral interaction. Then it uses a Machine Learning algorithm to build a model of the interface (in contrast to using a human specialist as in the fuzzing approach). Learning technique produces a better interface to simulate peripheral interaction, but it also depends on having the real hardware first to build the working model of the interface, and that also impede its scalability.

\section{Abstraction Replacement}

Abstraction Replacement takes a different approach and instead of trying to produce answers to hardware calls that are similar to the answers a real hardware would produce, this method tries to completely remove from the original firmware the hardware call, replacing it with another abstraction that does not require the real hardware.

In the work of \cite{halucinator}, they develop the method called {\tt Halucinator}, whose idea is to search for Hardware Abstraction Layer (HAL) libraries inside the firmware and replace those libraries with custom libraries implemented by the researchers that do not require peripherals to work. This method still require human intervention for each firmware and thus, does not scale.

In the other hand, the work of \cite{firmadyne} implements a tool called {\tt Firmadyne}, whose approach to re-hosting consists of replacing the original kernel found on the firmware image with a custom implemented and instrumented kernel worked by their team (the same kernel is used to all firmware images emulated, regardless their original kernel version). They can then emulate firmware at scale, with the counterpart that the kernel replacement sacrifices emulation fidelity.

%\subsection{Firmadyne}